{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c47ac430",
   "metadata": {},
   "source": [
    "# $\\color{ForestGreen}{\\text{A Toy Dataset for Classification}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "990754cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing basic libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb8aa8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing a dataset consisting 1000 samples with 10 features and 3 classes for the target \n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=4, n_redundant=0, n_classes=3, \n",
    "                            random_state=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ebe0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breaking the data into train and test subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78bb38a",
   "metadata": {},
   "source": [
    "## $\\color{ForestGreen}{\\text{Decision Tree Classifier}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db2e40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constructing tree classifier with no specified hyperparameters\n",
    "\n",
    "from sklearn import tree \n",
    "\n",
    "tr_clf = tree.DecisionTreeClassifier()\n",
    "tr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aa5f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the predictions of tree classifier for train and test subsets\n",
    "\n",
    "train_y_pred = tr_clf.predict(X_train)\n",
    "test_y_pred = tr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70c649b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Train Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       258\n",
      "           1       1.00      1.00      1.00       246\n",
      "           2       1.00      1.00      1.00       246\n",
      "\n",
      "    accuracy                           1.00       750\n",
      "   macro avg       1.00      1.00      1.00       750\n",
      "weighted avg       1.00      1.00      1.00       750\n",
      " \n",
      "\n",
      "\n",
      "Decision Tree Test Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.73        77\n",
      "           1       0.78      0.70      0.74        87\n",
      "           2       0.80      0.77      0.78        86\n",
      "\n",
      "    accuracy                           0.75       250\n",
      "   macro avg       0.75      0.75      0.75       250\n",
      "weighted avg       0.76      0.75      0.75       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "train_score = metrics.accuracy_score(y_train, train_y_pred)   # Compute train accuracy\n",
    "test_score = metrics.accuracy_score(y_test, test_y_pred)      # Compute test accuracy\n",
    "train_report = classification_report(y_train, train_y_pred)   # Generate classification report for train data\n",
    "test_report = classification_report(y_test, test_y_pred)      # Generate classification report for test data\n",
    "\n",
    "print('Decision Tree Train Classification Report: \\n\\n', train_report,'\\n\\n')\n",
    "print('Decision Tree Test Classification Report: \\n\\n', test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4229bf5c",
   "metadata": {},
   "source": [
    "## $\\color{ForestGreen}{\\text{Bagged Decision Trees Classifier}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58da6c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=18,\n",
       "                  random_state=3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constructing a bagged-tree classifier\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(base_estimator=tree.DecisionTreeClassifier(), n_estimators=18, random_state=3)\n",
    "bag_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6edddeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the predictions of the bagged-tree classifier for train and test subsets\n",
    "\n",
    "train_y_pred = bag_clf.predict(X_train)\n",
    "test_y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4935f52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged Trees Classifier Train Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       258\n",
      "           1       1.00      1.00      1.00       246\n",
      "           2       1.00      1.00      1.00       246\n",
      "\n",
      "    accuracy                           1.00       750\n",
      "   macro avg       1.00      1.00      1.00       750\n",
      "weighted avg       1.00      1.00      1.00       750\n",
      " \n",
      "\n",
      "\n",
      "Bagged Trees Classifier Test Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85        77\n",
      "           1       0.86      0.72      0.79        87\n",
      "           2       0.88      0.92      0.90        86\n",
      "\n",
      "    accuracy                           0.85       250\n",
      "   macro avg       0.85      0.85      0.85       250\n",
      "weighted avg       0.85      0.85      0.85       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score = metrics.accuracy_score(y_train, train_y_pred)   # Compute train accuracy\n",
    "test_score = metrics.accuracy_score(y_test, test_y_pred)      # Compute test accuracy\n",
    "train_report = classification_report(y_train, train_y_pred)   # Generate classification report for train data\n",
    "test_report = classification_report(y_test, test_y_pred)      # Generate classification report for test data\n",
    "\n",
    "print('Bagged Trees Classifier Train Classification Report: \\n\\n', train_report,'\\n\\n')\n",
    "print('Bagged Trees Classifier Test Classification Report: \\n\\n', test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6115321",
   "metadata": {},
   "source": [
    "## $\\color{ForestGreen}{\\text{Random Forest Classifier}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d00cf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constructing a random forest classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(max_depth=2, random_state=3)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13b0b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the predictions of random forest classifier for train and test subsets\n",
    "\n",
    "train_y_pred = rf_clf.predict(X_train)\n",
    "test_y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e7657b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Train Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81       258\n",
      "           1       0.86      0.50      0.63       246\n",
      "           2       0.73      0.84      0.78       246\n",
      "\n",
      "    accuracy                           0.75       750\n",
      "   macro avg       0.77      0.75      0.74       750\n",
      "weighted avg       0.77      0.75      0.74       750\n",
      " \n",
      "\n",
      "\n",
      "Random Forest Classifier Test Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.90      0.73        77\n",
      "           1       0.79      0.39      0.52        87\n",
      "           2       0.71      0.78      0.74        86\n",
      "\n",
      "    accuracy                           0.68       250\n",
      "   macro avg       0.70      0.69      0.66       250\n",
      "weighted avg       0.71      0.68      0.66       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score = metrics.accuracy_score(y_train, train_y_pred)   # Compute train accuracy\n",
    "test_score = metrics.accuracy_score(y_test, test_y_pred)      # Compute test accuracy\n",
    "train_report = classification_report(y_train, train_y_pred)   # Generate classification report for train data\n",
    "test_report = classification_report(y_test, test_y_pred)      # Generate classification report for test data\n",
    "\n",
    "print('Random Forest Classifier Train Classification Report: \\n\\n', train_report,'\\n\\n')\n",
    "print('Random Forest Classifier Test Classification Report: \\n\\n', test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bb5ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=6, max_leaf_nodes=8, n_estimators=3000,\n",
       "                       random_state=3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constructing a new random forest classifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=3000, max_depth=6, max_leaf_nodes=8, random_state=3)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a420f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the predictions of the new random forest classifier for train and test subsets\n",
    "\n",
    "train_y_pred = rf_clf.predict(X_train)\n",
    "test_y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9fe9b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Train Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       258\n",
      "           1       0.87      0.61      0.72       246\n",
      "           2       0.76      0.91      0.83       246\n",
      "\n",
      "    accuracy                           0.81       750\n",
      "   macro avg       0.82      0.81      0.80       750\n",
      "weighted avg       0.82      0.81      0.80       750\n",
      " \n",
      "\n",
      "\n",
      "Random Forest Classifier Test Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.80        77\n",
      "           1       0.84      0.54      0.66        87\n",
      "           2       0.74      0.87      0.80        86\n",
      "\n",
      "    accuracy                           0.76       250\n",
      "   macro avg       0.77      0.77      0.75       250\n",
      "weighted avg       0.77      0.76      0.75       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score = metrics.accuracy_score(y_train, train_y_pred)   # Compute train accuracy\n",
    "test_score = metrics.accuracy_score(y_test, test_y_pred)      # Compute test accuracy\n",
    "train_report = classification_report(y_train, train_y_pred)   # Generate classification report for train data\n",
    "test_report = classification_report(y_test, test_y_pred)      # Generate classification report for test data\n",
    "\n",
    "print('Random Forest Classifier Train Classification Report: \\n\\n', train_report,'\\n\\n')\n",
    "print('Random Forest Classifier Test Classification Report: \\n\\n', test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65f00eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating the feature importance\n",
    "\n",
    "feature_importance = rf_clf.feature_importances_\n",
    "feature_importance = 100.0*(feature_importance/np.sum(feature_importance))\n",
    "\n",
    "# Displaying the relative feature importance by a horizontal bar chart \n",
    "\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos=np.arange(sorted_idx.shape[0])+0.5\n",
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.barh(pos, feature_importance[sorted_idx], color='crimson', align=\"center\")\n",
    "plt.yticks(pos, np.array(['x_%d' %(i+1) for i in range(10)])[sorted_idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4e91e3",
   "metadata": {},
   "source": [
    "## $\\color{ForestGreen}{\\text{Bagged SVC Classifier}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fb57701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We start by training an SVC\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_clf = SVC()\n",
    "svc_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05a796e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the predictions of SVC classifier for train and test subsets\n",
    "\n",
    "train_y_pred = svc_clf.predict(X_train)\n",
    "test_y_pred = svc_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "712d4d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Classifier Train Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.88       258\n",
      "           1       0.90      0.87      0.89       246\n",
      "           2       0.91      0.99      0.95       246\n",
      "\n",
      "    accuracy                           0.91       750\n",
      "   macro avg       0.91      0.91      0.91       750\n",
      "weighted avg       0.91      0.91      0.91       750\n",
      " \n",
      "\n",
      "\n",
      "SVC Classifier Test Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83        77\n",
      "           1       0.90      0.74      0.81        87\n",
      "           2       0.84      0.97      0.90        86\n",
      "\n",
      "    accuracy                           0.85       250\n",
      "   macro avg       0.85      0.85      0.85       250\n",
      "weighted avg       0.85      0.85      0.85       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score = metrics.accuracy_score(y_train, train_y_pred)   # Compute train accuracy\n",
    "test_score = metrics.accuracy_score(y_test, test_y_pred)      # Compute test accuracy\n",
    "train_report = classification_report(y_train, train_y_pred)   # Generate classification report for train data\n",
    "test_report = classification_report(y_test, test_y_pred)      # Generate classification report for test data\n",
    "\n",
    "print('SVC Classifier Train Classification Report: \\n\\n', train_report,'\\n\\n')\n",
    "print('SVC Classifier Test Classification Report: \\n\\n', test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c5c3868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=SVC(), n_estimators=30, random_state=3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constructing a bagged-SVC classifier\n",
    "\n",
    "bag_clf = BaggingClassifier(base_estimator=SVC(), n_estimators=30, random_state=3)\n",
    "bag_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cf26ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the predictions of the bagged-SVC classifier for train and test subsets\n",
    "\n",
    "train_y_pred = bag_clf.predict(X_train)\n",
    "test_y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d35a16a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged SVC Classifier Train Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88       258\n",
      "           1       0.89      0.86      0.88       246\n",
      "           2       0.91      0.98      0.94       246\n",
      "\n",
      "    accuracy                           0.90       750\n",
      "   macro avg       0.90      0.90      0.90       750\n",
      "weighted avg       0.90      0.90      0.90       750\n",
      " \n",
      "\n",
      "\n",
      "Bagged SVC Classifier Test Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82        77\n",
      "           1       0.90      0.71      0.79        87\n",
      "           2       0.83      0.97      0.89        86\n",
      "\n",
      "    accuracy                           0.84       250\n",
      "   macro avg       0.84      0.84      0.84       250\n",
      "weighted avg       0.85      0.84      0.84       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score = metrics.accuracy_score(y_train, train_y_pred)   # Compute train accuracy\n",
    "test_score = metrics.accuracy_score(y_test, test_y_pred)      # Compute test accuracy\n",
    "train_report = classification_report(y_train, train_y_pred)   # Generate classification report for train data\n",
    "test_report = classification_report(y_test, test_y_pred)      # Generate classification report for test data\n",
    "\n",
    "print('Bagged SVC Classifier Train Classification Report: \\n\\n', train_report,'\\n\\n')\n",
    "print('Bagged SVC Classifier Test Classification Report: \\n\\n', test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f9b806",
   "metadata": {},
   "source": [
    "## $\\color{ForestGreen}{\\text{AdaBoost Classifier}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cb659b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_leaf_nodes=10),\n",
       "                   learning_rate=1.5, n_estimators=500, random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing AdaBoostClassifier from ensemble module\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Instantiating the AdaBoostClassifier with 500 sequential trees\n",
    "\n",
    "adab_clf = AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(max_leaf_nodes=10), \n",
    "                              n_estimators=500, learning_rate=1.5, random_state=0) \n",
    "adab_clf.fit(X_train, y_train)   # Fitting the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b48de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the predictions of the adaboost classifier for train and test subsets\n",
    "\n",
    "train_y_pred = adab_clf.predict(X_train)\n",
    "test_y_pred = adab_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0dec295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Train Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       258\n",
      "           1       0.93      0.98      0.96       246\n",
      "           2       0.99      0.97      0.98       246\n",
      "\n",
      "    accuracy                           0.97       750\n",
      "   macro avg       0.97      0.97      0.97       750\n",
      "weighted avg       0.97      0.97      0.97       750\n",
      " \n",
      "\n",
      "\n",
      "AdaBoost Classifier Test Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79        77\n",
      "           1       0.77      0.68      0.72        87\n",
      "           2       0.81      0.90      0.85        86\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.79      0.79      0.79       250\n",
      "weighted avg       0.79      0.79      0.79       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score = metrics.accuracy_score(y_train, train_y_pred)   # Compute train accuracy\n",
    "test_score = metrics.accuracy_score(y_test, test_y_pred)      # Compute test accuracy\n",
    "train_report = classification_report(y_train, train_y_pred)   # Generate classification report for train data\n",
    "test_report = classification_report(y_test, test_y_pred)      # Generate classification report for test data\n",
    "\n",
    "print('AdaBoost Classifier Train Classification Report: \\n\\n', train_report,'\\n\\n')\n",
    "print('AdaBoost Classifier Test Classification Report: \\n\\n', test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e7e54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
